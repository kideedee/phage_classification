{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T07:39:22.111595Z",
     "start_time": "2025-08-05T07:35:27.000697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "def aggregate_h5_files(data_dir, input_files, output_file):\n",
    "    \"\"\"\n",
    "    Aggregate multiple H5 files into a single file (memory efficient)\n",
    "    \"\"\"\n",
    "    # First pass: determine total dimensions\n",
    "    total_samples = 0\n",
    "    vector_shape = None\n",
    "    label_shape = None\n",
    "\n",
    "    print(\"Scanning files to determine dimensions...\")\n",
    "    for input_file in input_files:\n",
    "        input_path = os.path.join(data_dir, input_file)\n",
    "        with h5py.File(input_path, 'r') as f_in:\n",
    "            vectors = f_in['vectors']\n",
    "            labels = f_in['labels']\n",
    "\n",
    "            if vector_shape is None:\n",
    "                vector_shape = vectors.shape[1:]  # All dimensions except first\n",
    "                label_shape = labels.shape[1:] if len(labels.shape) > 1 else ()\n",
    "\n",
    "            total_samples += vectors.shape[0]\n",
    "            print(f\"  {input_file}: {vectors.shape[0]} samples\")\n",
    "\n",
    "    print(f\"Total samples to aggregate: {total_samples}\")\n",
    "    print(f\"Vector shape per sample: {vector_shape}\")\n",
    "\n",
    "    # Create output file with pre-allocated datasets\n",
    "    output_path = os.path.join(data_dir, output_file)\n",
    "    with h5py.File(output_path, 'w') as f_out:\n",
    "        # Create datasets with known total size\n",
    "        if len(vector_shape) > 0:\n",
    "            full_vector_shape = (total_samples,) + vector_shape\n",
    "        else:\n",
    "            full_vector_shape = (total_samples,)\n",
    "\n",
    "        if len(label_shape) > 0:\n",
    "            full_label_shape = (total_samples,) + label_shape\n",
    "        else:\n",
    "            full_label_shape = (total_samples,)\n",
    "\n",
    "        vectors_dset = f_out.create_dataset('vectors', shape=full_vector_shape,\n",
    "                                            dtype='float32')  # Adjust dtype as needed\n",
    "        labels_dset = f_out.create_dataset('labels', shape=full_label_shape,\n",
    "                                           dtype='int32')  # Adjust dtype as needed\n",
    "\n",
    "        # Second pass: copy data chunk by chunk\n",
    "        current_idx = 0\n",
    "        for i, input_file in enumerate(input_files):\n",
    "            input_path = os.path.join(data_dir, input_file)\n",
    "            print(f\"Processing {input_file}...\")\n",
    "\n",
    "            with h5py.File(input_path, 'r') as f_in:\n",
    "                vectors = f_in['vectors']\n",
    "                labels = f_in['labels']\n",
    "\n",
    "                num_samples = vectors.shape[0]\n",
    "                end_idx = current_idx + num_samples\n",
    "\n",
    "                # Copy data directly without loading into memory\n",
    "                vectors_dset[current_idx:end_idx] = vectors[:]\n",
    "                labels_dset[current_idx:end_idx] = labels[:]\n",
    "\n",
    "                current_idx = end_idx\n",
    "                print(f\"  Copied {num_samples} samples (total so far: {current_idx})\")\n",
    "\n",
    "        # # Add metadata\n",
    "        # f_out.attrs['source_files'] = [f.encode('utf-8') for f in input_files]\n",
    "        # f_out.attrs['num_source_files'] = len(input_files)\n",
    "        # f_out.attrs['total_samples'] = total_samples\n",
    "\n",
    "    print(f\"Successfully aggregated {len(input_files)} files into {output_file}\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "data_dir = \"E:\\\\master\\\\final_project\\\\data\\\\my_data\\\\embedding_output_data\\\\normalized_hdfs_pfcgr_embedding\\\\100_400\\\\fold_1\\\\test\"\n",
    "input_files = ['data_1.h5', 'data_2.h5', 'data_3.h5', 'data_4.h5', 'data_5.h5']\n",
    "aggregate_h5_files(data_dir, input_files, 'data.h5')"
   ],
   "id": "33e22e70d2e28f33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files to determine dimensions...\n",
      "  data_1.h5: 22916 samples\n",
      "  data_2.h5: 22916 samples\n",
      "  data_3.h5: 22916 samples\n",
      "  data_4.h5: 22916 samples\n",
      "  data_5.h5: 22920 samples\n",
      "Total samples to aggregate: 114584\n",
      "Vector shape per sample: (5, 64, 64)\n",
      "Processing data_1.h5...\n",
      "  Copied 22916 samples (total so far: 22916)\n",
      "Processing data_2.h5...\n",
      "  Copied 22916 samples (total so far: 45832)\n",
      "Processing data_3.h5...\n",
      "  Copied 22916 samples (total so far: 68748)\n",
      "Processing data_4.h5...\n",
      "  Copied 22916 samples (total so far: 91664)\n",
      "Processing data_5.h5...\n",
      "  Copied 22920 samples (total so far: 114584)\n",
      "Successfully aggregated 5 files into data.h5\n",
      "Total samples: 114584\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T05:32:22.065088Z",
     "start_time": "2025-08-05T05:31:47.592551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with h5py.File('C:\\\\Users\\Admin\\Temp\\\\100_400\\\\fold_1\\\\train\\data.h5', 'r') as f:\n",
    "    print(f['vectors'][:].shape)"
   ],
   "id": "abe897d90362abe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460632, 5, 64, 64)\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
